#Saif and azoz  (Dead Line : Monday )
"""
raid_calculations.py
Implements RAID calculation functions for performance metrics and capacity analysis.
Functions for Idea 5 (Multimedia Storage Performance Simulator):
- usable_capacity_percent(num_disks, raid_level) -> float
- redundancy_percent(num_disks, raid_level) -> float
- space_efficiency(num_disks, raid_level) -> float
- calculate_storage_overhead(total_bytes, raid_level, num_disks) -> dict
- estimate_access_time(file_size_bytes, num_disks, raid_level, base_transfer_rate_mbps=100) -> float

New functions from sec-5-1.pdf:
- get_write_penalty(raid_level) -> int
- calculate_disk_load_iops(total_iops, read_percent, write_percent, raid_level) -> float
- calculate_xor_parity(data_blocks) -> int
"""
import math


def usable_capacity_percent(num_disks, raid_level):
    """
    Calculate usable capacity as percentage of raw capacity.
    Formula from sec-5-1.pdf slides 13-20
    
    Args:
        num_disks: Number of disks in array
        raid_level: RAID level string ("RAID 0", "RAID 1", "RAID 5", "RAID 6")
    
    Returns:
        Percentage of usable capacity (0-100)
    
    Examples:
        >>> # RAID 0: 4 disks x 200GB = 800GB usable
        >>> usable_capacity_percent(4, "RAID 0")
        100.0
        >>> # RAID 1: 4 disks x 200GB = 400GB usable (50%)
        >>> usable_capacity_percent(4, "RAID 1")
        50.0
        >>> # RAID 5: 5 disks x 200GB = 800GB usable (80%)
        >>> usable_capacity_percent(5, "RAID 5")
        80.0
    """
    if num_disks < 2:
        raise ValueError("Number of disks must be at least 2")
    
    if raid_level == "RAID 0":
        return 100.0  # All capacity is usable
    elif raid_level == "RAID 1" or raid_level == "RAID 10":
        return 100.0 / num_disks  # Only 1/n is usable (mirroring)
    elif raid_level == "RAID 3" or raid_level == "RAID 4" or raid_level == "RAID 5":
        if num_disks < 3:
            raise ValueError("RAID 3/4/5 requires at least 3 disks")
        return ((num_disks - 1) / num_disks) * 100.0  # One disk worth for parity
    elif raid_level == "RAID 6":
        if num_disks < 4:
            raise ValueError("RAID 6 requires at least 4 disks")
        return ((num_disks - 2) / num_disks) * 100.0  # Two disks worth for dual parity
    else:
        raise ValueError(f"Unsupported RAID level: {raid_level}")


def redundancy_percent(num_disks, raid_level):
    """
    Calculate redundancy overhead as percentage of total capacity.
    to get the redundancy percent, we just subtract usable from 100.
    Args:
        num_disks: Number of disks in array
        raid_level: RAID level string ("RAID 0", "RAID 1", "RAID 5")
    Returns:
        Percentage of capacity used for redundancy (0-100)
    """
    return 100.0 - usable_capacity_percent(num_disks, raid_level)


def space_efficiency(num_disks, raid_level):
    """
    Calculate space efficiency ratio (usable / raw).
    tshl 3lina fe el calcs di 3ashan n3rf el efficiency bta3t el storage.
    Returns:
        Efficiency ratio (0.0-1.0)
    """
    return usable_capacity_percent(num_disks, raid_level) / 100.0


def get_write_penalty(raid_level):
    """
    Get the write penalty for a RAID level.
    Formula from sec-5-1.pdf slides 21-22.
    
    Write penalty represents the number of I/O operations required
    for each logical write operation:
    - RAID 0: 1 (no overhead)
    - RAID 1: 2 (write to both mirrors)
    - RAID 5: 4 (read data, read parity, write data, write parity)
    - RAID 6: 6 (read data, read 2 parities, write data, write 2 parities)
    
    Args:
        raid_level: RAID level string
    
    Returns:
        Write penalty as integer
    
    Example:
        >>> get_write_penalty("RAID 5")
        4
    """
    penalties = {
        "RAID 0": 1,   # No redundancy, direct write
        "RAID 1": 2,   # Write to both mirrors
        "RAID 10": 2,  # Same as RAID 1
        "RAID 3": 4,   # Read-modify-write for parity
        "RAID 4": 4,   # Read-modify-write for parity
        "RAID 5": 4,   # Read-modify-write for parity
        "RAID 6": 6    # Read-modify-write for dual parity
    }
    return penalties.get(raid_level, 1)


def calculate_disk_load_iops(total_iops, read_percent, write_percent, raid_level):
    """
    Calculate actual disk load in IOPS considering RAID write penalty.
    Formula from sec-5-1.pdf slides 22-23:
    
    Disk Load (IOPS) = (Total IOPS × Read %) + (Total IOPS × Write % × Write Penalty)
    
    Args:
        total_iops: Total IOPS generated by application
        read_percent: Percentage of reads (0-100)
        write_percent: Percentage of writes (0-100)
        raid_level: RAID level string
    
    Returns:
        Actual disk load in IOPS
    
    Example from sec-5-1.pdf slide 25:
        >>> # 400 IOPS, 75% read (3/4), 25% write (1/4), RAID 5
        >>> load = calculate_disk_load_iops(400, 75, 25, "RAID 5")
        >>> print(f"Disk load: {load:.0f} IOPS")
        Disk load: 700 IOPS
        >>> 
        >>> # Calculation: 400 * 0.75 + 400 * 0.25 * 4 = 300 + 400 = 700
    """
    # Convert percentages to decimals
    read_ratio = read_percent / 100.0
    write_ratio = write_percent / 100.0
    
    # Get write penalty for this RAID level
    write_penalty = get_write_penalty(raid_level)
    
    # Apply formula from sec-5-1.pdf
    disk_load = (total_iops * read_ratio) + (total_iops * write_ratio * write_penalty)
    
    return disk_load


def calculate_required_disks_for_iops(total_iops, read_percent, write_percent, 
                                        raid_level, iops_per_disk):
    """
    Calculate number of disks required to handle IOPS workload.
    Uses the disk load formula from sec-5-1.pdf slide 22.
    
    Args:
        total_iops: Total IOPS generated by application
        read_percent: Percentage of reads (0-100)
        write_percent: Percentage of writes (0-100)
        raid_level: RAID level string
        iops_per_disk: Maximum IOPS each disk can handle
    
    Returns:
        Number of disks required (rounded up)
    
    Example from sec-5-1.pdf slides 27-29:
        >>> # 5200 IOPS, 60% read, 40% write, RAID 5, 180 IOPS/disk
        >>> disks = calculate_required_disks_for_iops(5200, 60, 40, "RAID 5", 180)
        >>> print(f"Disks required: {disks}")
        Disks required: 64
        >>> 
        >>> # Same workload with RAID 1
        >>> disks = calculate_required_disks_for_iops(5200, 60, 40, "RAID 1", 180)
        >>> print(f"Disks required: {disks}")
        Disks required: 41
    """
    # Calculate actual disk load
    disk_load = calculate_disk_load_iops(total_iops, read_percent, write_percent, raid_level)
    
    # Divide by capacity per disk and round up
    required_disks = math.ceil(disk_load / iops_per_disk)
    
    return required_disks


def calculate_xor_parity(data_blocks):
    """
    Calculate XOR parity for data blocks.
    Formula from sec-5-1.pdf slide 9.
    
    XOR (exclusive OR) is used to calculate parity in RAID 5.
    Parity = D1 ⊕ D2 ⊕ D3 ⊕ ... ⊕ Dn
    
    Args:
        data_blocks: List of integers or binary strings representing data
    
    Returns:
        Parity value (integer)
    
    Example from sec-5-1.pdf slide 9:
        >>> # Binary data blocks
        >>> d1 = 0b10110010  # Disk 1: 10110010
        >>> d2 = 0b11001010  # Disk 2: 11001010
        >>> parity = calculate_xor_parity([d1, d2])
        >>> print(f"Parity: {bin(parity)}")
        Parity: 0b1111000
        >>> 
        >>> # To recover lost data: D1 = Parity ⊕ D2
        >>> recovered = parity ^ d2
        >>> print(f"Recovered D1: {bin(recovered)}")
        Recovered D1: 0b10110010
    """
    if not data_blocks:
        return 0
    
    # XOR all data blocks together
    parity = data_blocks[0]
    for block in data_blocks[1:]:
        parity ^= block
    
    return parity


def recover_failed_disk_xor(remaining_blocks, parity):
    """
    Recover data from a failed disk using XOR parity.
    Formula from sec-5-1.pdf slide 12: D3 = D1 ⊕ D2 ⊕ D4 ⊕ P
    
    Args:
        remaining_blocks: List of surviving data blocks
        parity: Parity block
    
    Returns:
        Recovered data block
    
    Example from sec-5-1.pdf:
        >>> # Stripe with values: D1=4, D2=6, D3=?, D4=7, Parity=18
        >>> # Formula: 4 + 6 + ? + 7 = 18, so ? = 1
        >>> # Using XOR: D3 = D1 ⊕ D2 ⊕ D4 ⊕ P
        >>> d1, d2, d4, p = 4, 6, 7, 18
        >>> recovered = recover_failed_disk_xor([d1, d2, d4], p)
        >>> print(f"Recovered D3: {recovered}")
        Recovered D3: 1
    """
    # XOR parity with all remaining blocks
    result = parity
    for block in remaining_blocks:
        result ^= block
    
    return result


def calculate_storage_overhead(total_bytes, raid_level, num_disks):
    """
    Calculate detailed storage breakdown for given data size.
    
    Args:
        total_bytes: Total size of data to store
        raid_level: RAID level string
        num_disks: Number of disks
    
    Returns:
        Dictionary with:
        - usable_bytes: Data that can be stored
        - parity_bytes: Space used for parity
        - mirror_bytes: Space used for mirroring
        - total_required_bytes: Total raw storage needed
        - efficiency_ratio: Usable/total ratio
    """
    efficiency = space_efficiency(num_disks, raid_level)
    
    if raid_level == "RAID 0":
        return {
            "usable_bytes": total_bytes,
            "parity_bytes": 0,
            "mirror_bytes": 0,
            "total_required_bytes": total_bytes,
            "efficiency_ratio": 1.0
        }
    elif raid_level == "RAID 1" or raid_level == "RAID 10":
        mirror_bytes = total_bytes * (num_disks - 1)
        return {
            "usable_bytes": total_bytes,
            "parity_bytes": 0,
            "mirror_bytes": mirror_bytes,
            "total_required_bytes": total_bytes * num_disks,
            "efficiency_ratio": efficiency
        }
    elif raid_level in ["RAID 3", "RAID 4", "RAID 5"]:
        parity_bytes = total_bytes / (num_disks - 1)
        return {
            "usable_bytes": total_bytes,
            "parity_bytes": parity_bytes,
            "mirror_bytes": 0,
            "total_required_bytes": total_bytes + parity_bytes,
            "efficiency_ratio": efficiency
        }
    elif raid_level == "RAID 6":
        parity_bytes = total_bytes * 2 / (num_disks - 2)
        return {
            "usable_bytes": total_bytes,
            "parity_bytes": parity_bytes,
            "mirror_bytes": 0,
            "total_required_bytes": total_bytes + parity_bytes,
            "efficiency_ratio": efficiency
        }
    else:
        raise ValueError(f"Unsupported RAID level: {raid_level}")


def estimate_access_time(file_size_bytes, num_disks, raid_level, base_transfer_rate_mbps=100):
    """
    service time
    Estimate access time for reading/writing files based on RAID level.
    Simplified model considering parallelism and overhead.
    
    Args:
        file_size_bytes: Size of file
        num_disks: Number of disks
        raid_level: RAID level string
        base_transfer_rate_mbps: Base transfer rate per disk (MB/s)
    
    Returns:
        Estimated time in seconds
    """
    file_size_mb = file_size_bytes / (1024 * 1024)
    
    if raid_level == "RAID 0":
        # Parallel striping across all disks
        effective_rate = base_transfer_rate_mbps * num_disks
        return file_size_mb / effective_rate
    
    elif raid_level == "RAID 1" or raid_level == "RAID 10":
        # Write to all disks (parallel), but limited by slowest
        # Read can be parallel from any disk
        # Use average: (write_time + read_time) / 2
        write_time = file_size_mb / base_transfer_rate_mbps  # All writes happen in parallel
        read_time = file_size_mb / (base_transfer_rate_mbps * num_disks)  # Can read from any
        return (write_time + read_time) / 2
    
    elif raid_level in ["RAID 3", "RAID 4", "RAID 5"]:
        # Striping across (n-1) data disks with parity overhead
        data_disks = num_disks - 1
        effective_rate = base_transfer_rate_mbps * data_disks * 0.85  # 15% parity overhead
        return file_size_mb / effective_rate
    
    elif raid_level == "RAID 6":
        # Striping across (n-2) data disks with dual parity overhead
        data_disks = num_disks - 2
        effective_rate = base_transfer_rate_mbps * data_disks * 0.75  # 25% dual parity overhead
        return file_size_mb / effective_rate
    
    else:
        # Fallback: single disk speed
        return file_size_mb / base_transfer_rate_mbps


def calculate_parallel_speedup(num_disks, raid_level):
    """
    Calculate theoretical speedup factor from parallelism.
    
    Returns:
        Speedup multiplier compared to single disk
    """
    if raid_level == "RAID 0":
        return num_disks  # Perfect parallelism
    elif raid_level == "RAID 1" or raid_level == "RAID 10":
        return num_disks * 0.5  # Can parallelize reads, not writes
    elif raid_level in ["RAID 3", "RAID 4", "RAID 5"]:
        return (num_disks - 1) * 0.85  # (n-1) data disks with parity overhead
    elif raid_level == "RAID 6":
        return (num_disks - 2) * 0.75  # (n-2) data disks with dual parity overhead
    else:
        return 1.0


def fault_tolerance_level(raid_level, num_disks=None):
    """
    Return number of disk failures that can be tolerated.
    
    Returns:
        Integer number of disk failures survivable
    """
    if raid_level == "RAID 0":
        return 0  # No fault tolerance
    elif raid_level == "RAID 1" or raid_level == "RAID 10":
        return num_disks - 1 if num_disks else 1  # Can lose all but one
    elif raid_level in ["RAID 3", "RAID 4", "RAID 5"]:
        return 1  # Can lose one disk
    elif raid_level == "RAID 6":
        return 2  # Can lose two disks
    else:
        return 0


def calculate_capacity_breakdown_dict(num_disks, raid_level):
    """
    Calculate capacity breakdown for visualization.
    
    Returns:
        Dictionary with 'usable', 'parity', 'mirror' disk counts
    """
    if raid_level == "RAID 0":
        return {"usable": num_disks, "parity": 0, "mirror": 0}
    elif raid_level == "RAID 1" or raid_level == "RAID 10":
        return {"usable": 1, "parity": 0, "mirror": num_disks - 1}
    elif raid_level in ["RAID 3", "RAID 4", "RAID 5"]:
        return {"usable": num_disks - 1, "parity": 1, "mirror": 0}
    elif raid_level == "RAID 6":
        return {"usable": num_disks - 2, "parity": 2, "mirror": 0}
    else:
        return {"usable": num_disks, "parity": 0, "mirror": 0}


def compare_raid_efficiency(num_disks, raid_levels=None):
    """
    Compare efficiency metrics across multiple RAID levels.
    
    Args:
        num_disks: Number of disks
        raid_levels: List of RAID level strings (default: ["RAID 0", "RAID 1", "RAID 5"])
    
    Returns:
        Dictionary mapping RAID level to efficiency metrics
    """
    if raid_levels is None:
        raid_levels = ["RAID 0", "RAID 1", "RAID 5", "RAID 6"]
    
    comparison = {}
    for raid in raid_levels:
        try:
            comparison[raid] = {
                "usable_percent": usable_capacity_percent(num_disks, raid),
                "redundancy_percent": redundancy_percent(num_disks, raid),
                "efficiency_ratio": space_efficiency(num_disks, raid),
                "speedup_factor": calculate_parallel_speedup(num_disks, raid),
                "fault_tolerance": fault_tolerance_level(raid, num_disks),
                "write_penalty": get_write_penalty(raid)
            }
        except ValueError as e:
            comparison[raid] = {"error": str(e)}
    
    return comparison


if __name__ == "__main__":
    # Example from sec-5-1.pdf slide 27-29
    print("=" * 60)
    print("RAID Write Penalty Example (from sec-5-1.pdf)")
    print("=" * 60)
    
    total_iops = 5200
    read_percent = 60
    write_percent = 40
    iops_per_disk = 180
    
    print(f"\nApplication Workload:")
    print(f"  Total IOPS: {total_iops}")
    print(f"  Read/Write: {read_percent}% / {write_percent}%")
    print(f"  Disk capacity: {iops_per_disk} IOPS each")
    
    for raid in ["RAID 5", "RAID 1"]:
        disk_load = calculate_disk_load_iops(total_iops, read_percent, write_percent, raid)
        required = calculate_required_disks_for_iops(total_iops, read_percent, write_percent, raid, iops_per_disk)
        
        print(f"\n{raid}:")
        print(f"  Write Penalty: {get_write_penalty(raid)}")
        print(f"  Disk Load: {disk_load:.0f} IOPS")
        print(f"  Disks Required: {required}")
    
    print("\n" + "=" * 60)
    print("XOR Parity Example (from sec-5-1.pdf slide 9)")
    print("=" * 60)
    
    d1 = 0b10110010
    d2 = 0b11001010
    parity = calculate_xor_parity([d1, d2])
    
    print(f"\nDisk 1: {bin(d1)} ({d1})")
    print(f"Disk 2: {bin(d2)} ({d2})")
    print(f"Parity: {bin(parity)} ({parity})")
    
    # Simulate disk 2 failure
    recovered = recover_failed_disk_xor([d1], parity)
    print(f"\nRecovered Disk 2: {bin(recovered)} ({recovered})")
    print(f"Match: {recovered == d2}")
